{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5fb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install keyring artifacts-keyring\n",
    "!{sys.executable} -m pip install --pre --upgrade --trusted-host pkgs.dev.azure.com --trusted-host pypi.org --trusted-host \"*.blob.core.windows.net\" --trusted-host files.pythonhosted.org --extra-index-url https://pkgs.dev.azure.com/mathco-products/_packaging/pip-codex-wf%40Local/pypi/simple/ \"codex-widget-factory<=0.1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags to identify this iteration when submitted\n",
    "# example: codex_tags = {'env': 'dev', 'region': 'USA', 'product_category': 'A'}\n",
    "\n",
    "codex_tags = {\n",
    "}\n",
    "\n",
    "from codex_widget_factory import utils\n",
    "results_json=[]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f68d0c",
   "metadata": {},
   "source": [
    "## Ingestion File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaefa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin code here\n",
    "#File ingestion from azure blob storage using connection credentials\n",
    "\n",
    "from codex_widget_factory.ingestion.file_system import get_ingested_data as ingestion_file_system_get_ingested_data\n",
    "\n",
    "response_0 = ingestion_file_system_get_ingested_data(file_path='Sales_Data.csv',\n",
    "                                                     datasource_type='azure_blob_storage',\n",
    "                                                     connection_uri='DefaultEndpointsProtocol=https;AccountName=coach;AccountKey=qtMAw9Z1T+1oOl+joMwfzdvnR0exMA4Qw50vniiaXOFvpOeFG7TP+g+DP4/iU7VKAUhirSpzrESvjF3U2Ld0KA==;EndpointSuffix=core.windows.net',\n",
    "                                                     container_name='ddrs11/aegon_nischal')\n",
    "results_json.append({\n",
    "                        'type': 'Ingestion',\n",
    "                        'name': 'File System',\n",
    "                        'component': 'get_ingested_data',\n",
    "                        'visual_results': utils.get_response_visuals(response_0),\n",
    "                        'metrics': False\n",
    "                    })\n",
    "\n",
    "\n",
    "display (response_0)\n",
    "\n",
    "#END WIDGET CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3787e2",
   "metadata": {},
   "source": [
    " ### Custom Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f06cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN CUSTOM CODE BELOW...\n",
    "\n",
    "\n",
    "# asking python to read the given values as missing values/ null values.\n",
    "missing_value = [\"nan\",\"#DIV/0!\",'Missing Values','Missing',' ','-','NA','N/A','NaN','na','#ref', np.nan] \n",
    "\n",
    "#response_0 = pd.read_csv('Sales_Data.csv', na_values = missing_value)\n",
    "response_0 = response_0.replace([\"nan\",\"#DIV/0!\",'Missing Values','Missing',' ','-','NA','N/A','NaN','na','#ref'],[np.nan]*11)\n",
    "\n",
    "#Finding which columns has missing values\n",
    "print('Columns and corresponding null values are:\\n', response_0.isnull().sum().sort_values(ascending = False))\n",
    "\n",
    "# Filling the NULL values in 'broker_percentage_lost_2yrs' with mean \n",
    "response_0['broker_percentage_lost_2yrs'].fillna(8.077246e+01,inplace = True)\n",
    "\n",
    "# Finding mode values to fill na values in,'Gen_Channel', 'MTP_Channel','primary' columns\n",
    "gen_channel = response_0['Gen_Channel'].mode()\n",
    "mtp_channel= response_0['MTP_Channel'].mode()\n",
    "primary= response_0['Primary_Excess'].mode()\n",
    "\n",
    "#Filling null values for 'Gen_Channel', 'MTP_Channel' & 'Primary_Excess'\n",
    "response_0['Gen_Channel'].fillna(gen_channel.values[0],inplace = True)\n",
    "response_0['MTP_Channel'].fillna(mtp_channel.values[0],inplace = True)\n",
    "response_0['Primary_Excess'].fillna(primary.values[0],inplace = True)\n",
    "\n",
    "#Checking if any null values exist\n",
    "print('After DATA CLEANING:\\n The Sum of Null Values In The Data Set is:', response_0.isnull().sum().sum())\n",
    "\n",
    "#dropping duplicate values\n",
    "response_0=pd.concat([response_0[\"Opportunity_18_ID\"].to_frame(),response_0.iloc[:,1:].drop_duplicates()],axis=1).dropna()\n",
    "\n",
    "#changing the format of date column from string to datetime\n",
    "response_0['Inception_Renewal_Date'] = pd.to_datetime(response_0['Inception_Renewal_Date'])\n",
    "\n",
    "#put your output in this response param for connecting to downstream widgets\n",
    "response_1 = response_0\n",
    "\n",
    "#END CUSTOM CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cfb1d",
   "metadata": {},
   "source": [
    "## Transformation Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8937d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN WIDGET CODE BELOW...\n",
    "# This function removes the outliers that are present in the column/dataset\n",
    "# Based on the interquartile range or replaces them with NaNs.\n",
    "    \n",
    "\n",
    "from codex_widget_factory.transformation.remove_outliers import get_transformed_data as transformation_remove_outliers_get_transformed_data\n",
    "response_2 = transformation_remove_outliers_get_transformed_data(df = response_1, dep_var = 'Won',col_names = ['gwp_lost_2yrs','gwp_won_2yrs','num_won_2yrs','num_lost_2yrs','num_uniqprod_2yrs','num_won_2yrs',\n",
    "                                                                                                               'num_lost_2yrs','num_wonnew_2yrs','num_quot_2yrs','num_existing','broker_contact_num_won_2yrs',\n",
    "                                                                                                               'broker_contact_days_since_last_lost','quot_not_won','num_lost_wo_subreceieved_2yrs',\n",
    "                                                                                                               'num_lost_postsub_2yrs','num_lost_postquot_2yrs','broker_days_since_last_won','broker_num_won_2yrs'])\n",
    "results_json.append({\n",
    "                      'type': 'Transformation',\n",
    "                      'name': 'Remove Outliers',\n",
    "                      'component': 'get_transformed_data',\n",
    "                      'visual_results': utils.get_response_visuals(response_2),\n",
    "                      'metrics': False\n",
    "                    })\n",
    "display(response_2)\n",
    "\n",
    "#utils.render_response(response_2)\n",
    "\n",
    "#END WIDGET CODE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a1e7cc",
   "metadata": {},
   "source": [
    "## Custom Bivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##BIVARIATE ANALYSIS\n",
    "#custom code for bivariate analysis report\n",
    "bivariate_factors = response_1.copy()\n",
    "bivariate_factors[\"temp\"] = 1\n",
    "import plotly.express as px\n",
    "\n",
    "def percentage_pivot(col,data):\n",
    "    '''\n",
    "    Bivariate Analysis\n",
    "    \n",
    "    Parameters:\n",
    "    col:Factors impacting the output variable\n",
    "    \n",
    "    Returns:\n",
    "    Bivariate charts for the given list of attributes\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    data_pivot = data.groupby([col,\"Stage\"], as_index = False)['temp'].sum()\n",
    "    data_pivot1= data.groupby([col], as_index = False)['temp'].sum()\n",
    "    data_pivot1 = data_pivot1.rename(columns = {\"temp\":\"sum\"})\n",
    "    data_pivot = pd.merge(data_pivot,data_pivot1,on = col,how = \"inner\")\n",
    "    data_pivot[\"Won\"] = data_pivot[\"temp\"]/data_pivot[\"sum\"]\n",
    "    return data_pivot\n",
    "\n",
    "#Tuple of factors that influence the output variable\n",
    "factors_list=('Line_of_Business','Appetite', 'OppCountry','Business_Type','Entity_Hierarchy_Level','Type','Entity_Record_Type','num_won_2yrs','num_uniqprod_2yrs',\n",
    "        'Gen_Channel','Product')\n",
    "\n",
    "\n",
    "def bivariate(element):\n",
    "    \"\"\"\n",
    "    Bivariate analysis\n",
    "    \n",
    "    Parameters:\n",
    "    Element:Factors from the tuple\n",
    "    \n",
    "    Returns:\n",
    "    Iterates through the tuple and returns bivariate charts for the given list of attributes\n",
    "    \n",
    "    \"\"\"\n",
    "    temp_df = percentage_pivot(col = element, data = bivariate_factors)\n",
    "    print(temp_df)\n",
    "    fig = px.bar(temp_df, x = element,y= \"Won\", barmode = 'stack',color = \"Stage\")\n",
    "    results_json.append({\n",
    "                          'type': 'Exploration Analysis',\n",
    "                          'name': 'Bivariate Report',\n",
    "                          'component': 'Stacked_'+str(element),\n",
    "                          'visual_results': utils.get_response_visuals({\"stacked\":fig}),\n",
    "                          'metrics': False\n",
    "                        })\n",
    "    fig.show()\n",
    "    \n",
    "list(map(bivariate,factors_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
